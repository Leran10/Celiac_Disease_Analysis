#!/usr/bin/env Rscript
# Confounder-Adjusted Temporal Heatmap for ALL adj.p < 0.05 ORFs
# Shows temporal patterns for all 1,845 significant ORFs
# Author: Generated by Claude
# Date: 2025-07-18

library(dplyr)
library(ggplot2)
library(pheatmap)
library(RColorBrewer)
library(limma)

# Set working directory
setwd("/Users/leranwang/Handley Lab Dropbox/16S/Celiac/Phage/phage_detection_pipeline_new_assembly/Orf/data/total/compositonal_analysis")

cat("=== ALL SIGNIFICANT ORFS TEMPORAL HEATMAP ===\n")
cat("Starting analysis at:", format(Sys.time()), "\n\n")

# ============================================================================
# PART 1: LOAD DATA
# ============================================================================

cat("1. Loading data...\n")

# Load limma DA results
limma_da_results <- read.csv("/Users/leranwang/Handley Lab Dropbox/16S/Celiac/Phage/phage_detection_pipeline_new_assembly/Orf/data/total/total_limma_results.csv", row.names = 1)

# Load diversity data for metadata
diversity_data <- read.csv("diversity_data_full.csv")

# Load original ORF abundance data
orf_data <- read.csv("/Users/leranwang/Handley Lab Dropbox/16S/Celiac/Phage/phage_detection_pipeline_new_assembly/Orf/data/total/orf.abundance.table_0.75_prevFiltered_temporal_cleaned_noX.csv", row.names = 1)

# Clean ORF sample names
orf_samples <- colnames(orf_data)
orf_samples_clean <- gsub("^X", "", orf_samples)
colnames(orf_data) <- orf_samples_clean

cat("Data loaded:\n")
cat("  Limma results:", nrow(limma_da_results), "ORFs\n")
cat("  Diversity data:", nrow(diversity_data), "samples\n")
cat("  ORF abundance data:", nrow(orf_data), "ORFs,", ncol(orf_data), "samples\n")

# ============================================================================
# PART 2: GET ALL SIGNIFICANT ORFS
# ============================================================================

cat("\n2. Selecting all significant ORFs (adj.p < 0.05)...\n")

# Get ALL significant ORFs at 0.05 threshold
limma_da_results$significant <- limma_da_results$adj.P.Val < 0.05
all_sig_orfs <- limma_da_results[limma_da_results$significant, ]

cat("Total significant ORFs:", nrow(all_sig_orfs), "\n")
cat("Percentage of total:", round(100 * nrow(all_sig_orfs) / nrow(limma_da_results), 1), "%\n")

# Get samples that match ORF data
common_samples <- intersect(orf_samples_clean, diversity_data$sample_id)
diversity_matched <- diversity_data[diversity_data$sample_id %in% common_samples, ]
orf_data_matched <- orf_data[, common_samples]

cat("Matched samples:", length(common_samples), "\n")

# ============================================================================
# PART 3: FIT MODELS FOR ALL SIGNIFICANT ORFS (BATCH PROCESSING)
# ============================================================================

cat("\n3. Fitting models for all significant ORFs (this may take a few minutes)...\n")

# Function to fit model for a single ORF (optimized version)
fit_orf_temporal_model_fast <- function(orf_id, abundance_data, metadata) {
  
  # Get abundance for this ORF
  orf_abundances <- abundance_data[orf_id, ]
  
  # Create data frame for analysis
  model_data <- data.frame(
    sample_id = names(orf_abundances),
    abundance = as.numeric(orf_abundances),
    stringsAsFactors = FALSE
  )
  
  # Merge with metadata
  model_data <- merge(model_data, metadata, by = "sample_id")
  
  # Remove samples with missing data
  model_data <- model_data[complete.cases(model_data[, c("abundance", "Dx.Status", "onset_timeline_numeric", 
                                                         "Country", "Sex", "Age.at.Gluten.Introduction..months.", 
                                                         "HLA.Category", "feeding_first_year", "Delivery.Mode")]), ]
  
  if(nrow(model_data) < 20) {
    return(NULL)  # Skip ORFs with insufficient data
  }
  
  # Fit the model
  tryCatch({
    model <- lm(abundance ~ Dx.Status * onset_timeline_numeric + 
                  Country + Sex + Age.at.Gluten.Introduction..months. + 
                  HLA.Category + feeding_first_year + Delivery.Mode, 
                data = model_data)
    
    # Extract fitted values and original data
    model_data$fitted_abundance <- fitted(model)
    
    return(model_data)
    
  }, error = function(e) {
    return(NULL)
  })
}

# Batch process all significant ORFs (with progress tracking)
orf_model_results <- list()
orf_ids_to_analyze <- intersect(rownames(all_sig_orfs), rownames(orf_data_matched))

cat("Fitting models for", length(orf_ids_to_analyze), "ORFs...\n")

# Process in batches to show progress
batch_size <- 100
n_batches <- ceiling(length(orf_ids_to_analyze) / batch_size)

for(batch in 1:n_batches) {
  start_idx <- (batch - 1) * batch_size + 1
  end_idx <- min(batch * batch_size, length(orf_ids_to_analyze))
  batch_orfs <- orf_ids_to_analyze[start_idx:end_idx]
  
  for(orf_id in batch_orfs) {
    result <- fit_orf_temporal_model_fast(orf_id, orf_data_matched, diversity_matched)
    if(!is.null(result)) {
      orf_model_results[[orf_id]] <- result
    }
  }
  
  cat("Completed batch", batch, "of", n_batches, "- processed", length(orf_model_results), "ORFs so far\n")
}

cat("Successfully fitted models for", length(orf_model_results), "ORFs\n")

# ============================================================================
# PART 4: CREATE TEMPORAL DIFFERENCE MATRIX FOR ALL ORFS
# ============================================================================

cat("\n4. Calculating temporal differences for all ORFs...\n")

# Use actual study timepoints instead of artificial bins
actual_timepoints <- c(0, -6, -12, -18, -24, -30, -36, -42, -48, -54, -60, -66, -72)
time_bins <- sort(actual_timepoints, decreasing = FALSE)  # Sort from most negative to 0

# Function to calculate adjusted temporal differences (using exact timepoints)
calculate_all_temporal_differences <- function(model_results, time_bins) {
  
  # Pre-allocate matrix
  heatmap_matrix <- matrix(NA, 
                          nrow = length(model_results), 
                          ncol = length(time_bins),
                          dimnames = list(names(model_results), 
                                         ifelse(time_bins == 0, "T0", paste0("T0", time_bins))))
  
  for(i in 1:length(model_results)) {
    orf_id <- names(model_results)[i]
    orf_data <- model_results[[orf_id]]
    
    # Assign samples to exact timepoints (with small tolerance for rounding)
    orf_data$time_bin <- NA
    for(timepoint in time_bins) {
      matches <- abs(orf_data$onset_timeline_numeric - timepoint) < 1  # 1 month tolerance
      orf_data$time_bin[matches] <- timepoint
    }
    
    for(j in 1:length(time_bins)) {
      timepoint <- time_bins[j]
      
      # Get fitted abundances for this exact timepoint
      time_data <- orf_data[!is.na(orf_data$time_bin) & orf_data$time_bin == timepoint, ]
      
      if(nrow(time_data) >= 4) {  # Require at least 4 samples total
        # Calculate mean fitted abundances by group
        group_means <- time_data %>%
          group_by(Dx.Status) %>%
          summarise(
            mean_fitted_abundance = mean(fitted_abundance, na.rm = TRUE),
            n_samples = n(),
            .groups = "drop"
          ) %>%
          filter(n_samples >= 1)  # At least 1 sample per group
        
        # Calculate difference: CELIAC - CONTROL
        if(nrow(group_means) == 2) {
          celiac_fitted <- group_means$mean_fitted_abundance[group_means$Dx.Status == "CELIAC"]
          control_fitted <- group_means$mean_fitted_abundance[group_means$Dx.Status == "CONTROL"]
          
          if(length(celiac_fitted) > 0 && length(control_fitted) > 0) {
            heatmap_matrix[i, j] <- celiac_fitted - control_fitted
          }
        }
      }
    }
    
    # Progress update
    if(i %% 200 == 0) {
      cat("Processed", i, "of", length(model_results), "ORFs for temporal differences\n")
    }
  }
  
  return(heatmap_matrix)
}

# Calculate temporal differences for all ORFs
all_temporal_matrix <- calculate_all_temporal_differences(orf_model_results, time_bins)

cat("Temporal matrix dimensions:", dim(all_temporal_matrix), "\n")

# Remove rows with insufficient temporal data
valid_rows <- rowSums(!is.na(all_temporal_matrix)) >= 3
all_temporal_clean <- all_temporal_matrix[valid_rows, , drop = FALSE]

cat("Matrix after removing sparse rows:", dim(all_temporal_clean), "\n")

# ============================================================================
# PART 5: GENERATE COMPREHENSIVE HEATMAPS
# ============================================================================

cat("\n5. Generating heatmaps for all significant ORFs...\n")

if(nrow(all_temporal_clean) > 0) {
  
  # Apply log2 transformation for better visualization
  all_temporal_log <- all_temporal_clean
  all_temporal_log[is.na(all_temporal_log)] <- 0
  all_temporal_log <- sign(all_temporal_log) * log2(abs(all_temporal_log) + 1)
  
  cat("Scale after log transformation: min =", round(min(all_temporal_log, na.rm = TRUE), 2),
      "max =", round(max(all_temporal_log, na.rm = TRUE), 2), "\n")
  
  # Heatmap 1: Full heatmap (all ORFs, no row names due to size)
  png("all_significant_orfs_temporal_heatmap.png", width = 1400, height = 2000, res = 150)
  
  color_palette <- colorRampPalette(c("#2166AC", "#4393C3", "#92C5DE", "#D1E5F0", 
                                     "white", 
                                     "#FDBF6F", "#FF7F00", "#E31A1C", "#B2182B"))(100)
  
  max_abs_val <- max(abs(all_temporal_log), na.rm = TRUE)
  break_range <- min(max_abs_val, 4)
  breaks <- seq(-break_range, break_range, length.out = 101)
  
  pheatmap(
    all_temporal_log,
    cluster_rows = TRUE,
    cluster_cols = FALSE,
    scale = "none",
    color = color_palette,
    main = paste("All Significant ORFs Temporal Patterns:", nrow(all_temporal_log), "ORFs\n(adj.p < 0.05, Log2-transformed, Red = Higher in CELIAC, Blue = Higher in CONTROL)"),
    fontsize = 8,
    fontsize_row = 0,  # No row names due to size
    fontsize_col = 10,
    show_rownames = FALSE,
    breaks = breaks,
    na_col = "grey90"
  )
  
  dev.off()
  
  cat("Generated full heatmap for all", nrow(all_temporal_log), "significant ORFs\n")
  
  # Heatmap 2: Summary by clustering (identify major patterns)
  # Perform clustering and summarize patterns
  if(nrow(all_temporal_log) > 10) {
    
    # Cluster ORFs and identify major groups
    row_clusters <- cutree(hclust(dist(all_temporal_log)), k = min(10, max(3, round(nrow(all_temporal_log)/200))))
    
    # Calculate cluster centroids
    cluster_centroids <- matrix(NA, nrow = length(unique(row_clusters)), ncol = ncol(all_temporal_log))
    rownames(cluster_centroids) <- paste0("Cluster_", sort(unique(row_clusters)))
    colnames(cluster_centroids) <- colnames(all_temporal_log)
    
    for(cluster_id in sort(unique(row_clusters))) {
      cluster_orfs <- names(row_clusters)[row_clusters == cluster_id]
      if(length(cluster_orfs) > 1) {
        cluster_centroids[paste0("Cluster_", cluster_id), ] <- colMeans(all_temporal_log[cluster_orfs, , drop = FALSE], na.rm = TRUE)
      } else {
        cluster_centroids[paste0("Cluster_", cluster_id), ] <- all_temporal_log[cluster_orfs, ]
      }
    }
    
    # Plot cluster summary
    png("all_significant_orfs_cluster_summary.png", width = 1200, height = 800, res = 150)
    
    pheatmap(
      cluster_centroids,
      cluster_rows = TRUE,
      cluster_cols = FALSE,
      scale = "none",
      color = color_palette,
      main = paste("Temporal Pattern Clusters from", nrow(all_temporal_log), "Significant ORFs\n(Cluster centroids show major patterns)"),
      fontsize = 10,
      fontsize_row = 10,
      fontsize_col = 12,
      show_rownames = TRUE,
      breaks = breaks,
      na_col = "grey90"
    )
    
    # Add cluster size annotations
    cluster_sizes <- table(row_clusters)
    for(i in 1:length(cluster_sizes)) {
      cluster_name <- paste0("Cluster_", names(cluster_sizes)[i])
      cat("Cluster", names(cluster_sizes)[i], ":", cluster_sizes[i], "ORFs\n")
    }
    
    dev.off()
    
    cat("Generated cluster summary heatmap with", length(unique(row_clusters)), "major patterns\n")
  }
  
  # Heatmap 3: Sample subset with ORF names visible (top 200 most variable)
  temporal_variance <- apply(all_temporal_log, 1, var, na.rm = TRUE)
  top_variable_orfs <- names(sort(temporal_variance, decreasing = TRUE))[1:min(200, length(temporal_variance))]
  top_variable_matrix <- all_temporal_log[top_variable_orfs, , drop = FALSE]
  
  png("top_variable_significant_orfs_heatmap.png", width = 1400, height = 1600, res = 150)
  
  pheatmap(
    top_variable_matrix,
    cluster_rows = TRUE,
    cluster_cols = FALSE,
    scale = "none",
    color = color_palette,
    main = paste("Top", nrow(top_variable_matrix), "Most Variable Significant ORFs\n(Highest temporal variance, names visible)"),
    fontsize = 8,
    fontsize_row = 4,
    fontsize_col = 10,
    show_rownames = TRUE,
    breaks = breaks,
    na_col = "grey90"
  )
  
  dev.off()
  
  cat("Generated heatmap for top", nrow(top_variable_matrix), "most variable ORFs\n")
  
} else {
  cat("No valid data for heatmap generation\n")
}

# ============================================================================
# PART 6: SAVE RESULTS AND SUMMARY
# ============================================================================

cat("\n6. Saving results...\n")

# Save the full temporal matrix
write.csv(all_temporal_clean, "all_significant_orfs_temporal_matrix.csv")

# Create summary statistics
if(nrow(all_temporal_clean) > 0) {
  summary_stats <- data.frame(
    metric = c("total_significant_orfs", "orfs_with_temporal_data", "orfs_analyzed", 
               "mean_temporal_difference", "median_temporal_difference",
               "max_temporal_difference", "min_temporal_difference"),
    value = c(nrow(all_sig_orfs), nrow(all_temporal_matrix), nrow(all_temporal_clean),
              mean(all_temporal_clean, na.rm = TRUE), median(all_temporal_clean, na.rm = TRUE),
              max(all_temporal_clean, na.rm = TRUE), min(all_temporal_clean, na.rm = TRUE))
  )
  
  write.csv(summary_stats, "all_significant_orfs_summary_stats.csv", row.names = FALSE)
}

cat("\nAll significant ORFs temporal analysis completed successfully!\n")
cat("Generated files:\n")
cat("- all_significant_orfs_temporal_heatmap.png: Full heatmap of all", nrow(all_temporal_clean), "ORFs\n")
cat("- all_significant_orfs_cluster_summary.png: Major temporal patterns summary\n")
cat("- top_variable_significant_orfs_heatmap.png: Top 200 most variable ORFs with names\n")
cat("- all_significant_orfs_temporal_matrix.csv: Raw data matrix\n")
cat("- all_significant_orfs_summary_stats.csv: Summary statistics\n")

cat("\nAnalysis completed at:", format(Sys.time()), "\n")