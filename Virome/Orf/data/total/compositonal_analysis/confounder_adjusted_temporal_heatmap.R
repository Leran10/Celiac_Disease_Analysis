#!/usr/bin/env Rscript
# Confounder-Adjusted Temporal Heatmap Analysis
# Shows model-based, confounder-adjusted abundance differences across time
# Author: Generated by Claude
# Date: 2025-07-18

library(dplyr)
library(ggplot2)
library(pheatmap)
library(RColorBrewer)
library(limma)

# Set working directory
setwd("/Users/leranwang/Handley Lab Dropbox/16S/Celiac/Phage/phage_detection_pipeline_new_assembly/Orf/data/total/compositonal_analysis")

cat("=== CONFOUNDER-ADJUSTED TEMPORAL HEATMAP ANALYSIS ===\n")
cat("Starting analysis at:", format(Sys.time()), "\n\n")

# ============================================================================
# PART 1: LOAD DATA
# ============================================================================

cat("1. Loading data...\n")

# Load your limma DA results
limma_da_results <- read.csv("/Users/leranwang/Handley Lab Dropbox/16S/Celiac/Phage/phage_detection_pipeline_new_assembly/Orf/data/total/total_limma_results.csv", row.names = 1)

# Load diversity data for metadata
diversity_data <- read.csv("diversity_data_full.csv")

# Load original ORF abundance data
orf_data <- read.csv("/Users/leranwang/Handley Lab Dropbox/16S/Celiac/Phage/phage_detection_pipeline_new_assembly/Orf/data/total/orf.abundance.table_0.75_prevFiltered_temporal_cleaned_noX.csv", row.names = 1)

# Clean ORF sample names
orf_samples <- colnames(orf_data)
orf_samples_clean <- gsub("^X", "", orf_samples)
colnames(orf_data) <- orf_samples_clean

cat("Data loaded:\n")
cat("  Limma results:", nrow(limma_da_results), "ORFs\n")
cat("  Diversity data:", nrow(diversity_data), "samples\n")
cat("  ORF abundance data:", nrow(orf_data), "ORFs,", ncol(orf_data), "samples\n")

# ============================================================================
# PART 2: PREPARE SIGNIFICANT ORFS AND MATCHED DATA
# ============================================================================

cat("\n2. Preparing significant ORFs and matched data...\n")

# Get significant ORFs (top 50 for computational efficiency)
limma_da_results$significant <- limma_da_results$adj.P.Val < 0.05
sig_orfs <- limma_da_results[limma_da_results$significant, ]
top_n <- min(50, nrow(sig_orfs))  # Use top 50 for efficiency
top_sig_orfs <- sig_orfs[order(sig_orfs$adj.P.Val), ][1:top_n, ]

cat("Using top", nrow(top_sig_orfs), "most significant ORFs for analysis\n")

# Get samples that match ORF data
common_samples <- intersect(orf_samples_clean, diversity_data$sample_id)
diversity_matched <- diversity_data[diversity_data$sample_id %in% common_samples, ]
orf_data_matched <- orf_data[, common_samples]

cat("Matched samples:", length(common_samples), "\n")

# ============================================================================
# PART 3: FIT LIMMA MODELS FOR EACH ORF AND EXTRACT FITTED VALUES
# ============================================================================

cat("\n3. Fitting limma models for each ORF...\n")

# Function to fit limma model for a single ORF and extract fitted values
fit_orf_temporal_model <- function(orf_id, abundance_data, metadata) {
  
  # Get abundance for this ORF
  orf_abundances <- abundance_data[orf_id, ]
  
  # Create data frame for analysis
  model_data <- data.frame(
    sample_id = names(orf_abundances),
    abundance = as.numeric(orf_abundances),
    stringsAsFactors = FALSE
  )
  
  # Merge with metadata
  model_data <- merge(model_data, metadata, by = "sample_id")
  
  # Remove samples with missing data
  model_data <- model_data[complete.cases(model_data[, c("abundance", "Dx.Status", "onset_timeline_numeric", 
                                                         "Country", "Sex", "Age.at.Gluten.Introduction..months.", 
                                                         "HLA.Category", "feeding_first_year", "Delivery.Mode")]), ]
  
  if(nrow(model_data) < 20) {
    return(NULL)  # Skip ORFs with insufficient data
  }
  
  # Fit the same model as your limma analysis
  # abundance ~ Dx.Status * onset_timeline_numeric + confounders
  tryCatch({
    model <- lm(abundance ~ Dx.Status * onset_timeline_numeric + 
                  Country + Sex + Age.at.Gluten.Introduction..months. + 
                  HLA.Category + feeding_first_year + Delivery.Mode, 
                data = model_data)
    
    # Extract fitted values and original data
    model_data$fitted_abundance <- fitted(model)
    
    return(model_data)
    
  }, error = function(e) {
    cat("Error fitting model for", orf_id, ":", e$message, "\n")
    return(NULL)
  })
}

# Fit models for all top significant ORFs
orf_model_results <- list()
orf_ids_to_analyze <- intersect(rownames(top_sig_orfs), rownames(orf_data_matched))

cat("Fitting models for", length(orf_ids_to_analyze), "ORFs...\n")

for(orf_id in orf_ids_to_analyze) {
  result <- fit_orf_temporal_model(orf_id, orf_data_matched, diversity_matched)
  if(!is.null(result)) {
    orf_model_results[[orf_id]] <- result
  }
  
  if(length(orf_model_results) %% 10 == 0) {
    cat("Processed", length(orf_model_results), "ORFs\n")
  }
}

cat("Successfully fitted models for", length(orf_model_results), "ORFs\n")

# ============================================================================
# PART 4: CREATE TIME BINS AND CALCULATE CONFOUNDER-ADJUSTED DIFFERENCES
# ============================================================================

cat("\n4. Calculating confounder-adjusted temporal differences...\n")

# Define time bins (same as before)
time_bins <- seq(-69, -3, by = 6)
cat("Time bins:", paste(time_bins, collapse = ", "), "\n")

# Function to calculate model-adjusted differences at each time point
calculate_adjusted_temporal_differences <- function(model_results, time_bins) {
  
  # Create matrix for results
  heatmap_matrix <- matrix(NA, 
                          nrow = length(model_results), 
                          ncol = length(time_bins),
                          dimnames = list(names(model_results), 
                                         paste0("T", time_bins)))
  
  for(i in 1:length(model_results)) {
    orf_id <- names(model_results)[i]
    orf_data <- model_results[[orf_id]]
    
    # Create time bins for this ORF
    orf_data$time_bin <- cut(orf_data$onset_timeline_numeric, 
                            breaks = c(-Inf, time_bins + 3, Inf), 
                            labels = c(time_bins, "late"),
                            include.lowest = TRUE)
    
    for(j in 1:length(time_bins)) {
      time_label <- as.character(time_bins[j])
      
      # Get fitted abundances (confounder-adjusted) for this time bin
      time_data <- orf_data[orf_data$time_bin == time_label & !is.na(orf_data$time_bin), ]
      
      if(nrow(time_data) > 0) {
        # Calculate mean fitted abundances by group (these are confounder-adjusted)
        group_means <- time_data %>%
          group_by(Dx.Status) %>%
          summarise(
            mean_fitted_abundance = mean(fitted_abundance, na.rm = TRUE),
            n_samples = n(),
            .groups = "drop"
          ) %>%
          filter(n_samples >= 2)  # Require at least 2 samples per group
        
        # Calculate difference: CELIAC - CONTROL (in fitted, confounder-adjusted space)
        if(nrow(group_means) == 2) {
          celiac_fitted <- group_means$mean_fitted_abundance[group_means$Dx.Status == "CELIAC"]
          control_fitted <- group_means$mean_fitted_abundance[group_means$Dx.Status == "CONTROL"]
          
          if(length(celiac_fitted) > 0 && length(control_fitted) > 0) {
            # Difference in confounder-adjusted abundances
            # Positive = higher in CELIAC, negative = higher in CONTROL
            heatmap_matrix[i, j] <- celiac_fitted - control_fitted
          }
        }
      }
    }
  }
  
  return(heatmap_matrix)
}

# Calculate the confounder-adjusted temporal differences
adjusted_diff_matrix <- calculate_adjusted_temporal_differences(orf_model_results, time_bins)

cat("Confounder-adjusted difference matrix dimensions:", dim(adjusted_diff_matrix), "\n")

# Remove rows with all NA values
valid_rows <- rowSums(!is.na(adjusted_diff_matrix)) >= 3  # Require at least 3 time points
adjusted_diff_clean <- adjusted_diff_matrix[valid_rows, , drop = FALSE]

cat("Matrix after removing sparse rows:", dim(adjusted_diff_clean), "\n")

# ============================================================================
# PART 5: GENERATE CONFOUNDER-ADJUSTED TEMPORAL HEATMAP
# ============================================================================

cat("\n5. Generating confounder-adjusted temporal heatmap...\n")

if(nrow(adjusted_diff_clean) > 0) {
  
  # Replace remaining NA values with 0 for visualization
  adjusted_diff_viz <- adjusted_diff_clean
  adjusted_diff_viz[is.na(adjusted_diff_viz)] <- 0
  
  # Create heatmap
  png("confounder_adjusted_temporal_heatmap.png", width = 1400, height = 1600, res = 150)
  
  # Color palette: Red = higher in CELIAC, Blue = higher in CONTROL
  color_palette <- colorRampPalette(c("blue", "white", "red"))(100)
  
  # Calculate symmetric breaks around zero
  max_abs_val <- max(abs(adjusted_diff_viz), na.rm = TRUE)
  breaks <- seq(-max_abs_val, max_abs_val, length.out = 101)
  
  pheatmap(
    adjusted_diff_viz,
    cluster_rows = TRUE,
    cluster_cols = FALSE,
    scale = "none",
    color = color_palette,
    main = paste("Confounder-Adjusted Temporal Differences:", nrow(adjusted_diff_viz), "ORFs\n(Red = Higher in CELIAC, Blue = Higher in CONTROL)\nModel-based, adjusted for all confounders"),
    fontsize = 8,
    fontsize_row = 6,
    fontsize_col = 10,
    show_rownames = TRUE,
    breaks = breaks
  )
  
  dev.off()
  
  cat("Generated confounder-adjusted temporal heatmap\n")
  
} else {
  cat("No valid data for heatmap generation\n")
}

# ============================================================================
# PART 6: VALIDATION AGAINST LIMMA RESULTS
# ============================================================================

cat("\n6. Validating against limma results...\n")

# For each ORF, calculate the overall temporal trend (slope of differences over time)
# This should correlate with the limma logFC results

validation_results <- data.frame(
  orf_id = character(),
  temporal_slope = numeric(),
  limma_logfc = numeric(),
  limma_pvalue = numeric(),
  limma_adj_pvalue = numeric(),
  stringsAsFactors = FALSE
)

for(orf_id in rownames(adjusted_diff_clean)) {
  if(orf_id %in% rownames(limma_da_results)) {
    
    # Get temporal differences for this ORF
    orf_diffs <- adjusted_diff_clean[orf_id, ]
    valid_diffs <- orf_diffs[!is.na(orf_diffs)]
    valid_times <- as.numeric(gsub("T", "", names(valid_diffs)))
    
    if(length(valid_diffs) >= 3) {
      # Fit linear trend to the temporal differences
      temporal_model <- lm(valid_diffs ~ valid_times)
      temporal_slope <- coef(temporal_model)[2]
      
      # Get limma results for this ORF
      limma_logfc <- limma_da_results[orf_id, "logFC"]
      limma_pvalue <- limma_da_results[orf_id, "P.Value"]
      limma_adj_pvalue <- limma_da_results[orf_id, "adj.P.Val"]
      
      validation_results <- rbind(validation_results, data.frame(
        orf_id = orf_id,
        temporal_slope = temporal_slope,
        limma_logfc = limma_logfc,
        limma_pvalue = limma_pvalue,
        limma_adj_pvalue = limma_adj_pvalue,
        stringsAsFactors = FALSE
      ))
    }
  }
}

# Calculate correlation between temporal slopes and limma logFC
if(nrow(validation_results) > 0) {
  correlation <- cor(validation_results$temporal_slope, validation_results$limma_logfc, use = "complete.obs")
  cat("Correlation between temporal slopes and limma logFC:", round(correlation, 3), "\n")
  
  # Create validation plot
  png("temporal_vs_limma_validation.png", width = 1000, height = 800, res = 150)
  
  plot(validation_results$limma_logfc, validation_results$temporal_slope,
       xlab = "Limma LogFC (CONTROL vs CELIAC)",
       ylab = "Temporal Slope (Confounder-adjusted)",
       main = paste("Validation: Temporal Slopes vs Limma Results\nCorrelation =", round(correlation, 3)),
       pch = 16, col = "blue", alpha = 0.6)
  
  # Add correlation line
  abline(lm(validation_results$temporal_slope ~ validation_results$limma_logfc), col = "red", lwd = 2)
  
  # Add text with correlation
  text(x = min(validation_results$limma_logfc), y = max(validation_results$temporal_slope),
       labels = paste("r =", round(correlation, 3)), col = "red", cex = 1.2)
  
  dev.off()
  
  cat("Generated validation plot\n")
}

# ============================================================================
# PART 7: SAVE RESULTS
# ============================================================================

cat("\n7. Saving results...\n")

# Save the adjusted difference matrix
write.csv(adjusted_diff_clean, "confounder_adjusted_temporal_matrix.csv")

# Save validation results
if(nrow(validation_results) > 0) {
  write.csv(validation_results, "temporal_limma_validation.csv", row.names = FALSE)
}

# Save summary statistics
if(nrow(adjusted_diff_clean) > 0) {
  summary_stats <- data.frame(
    metric = c("total_orfs_analyzed", "orfs_with_valid_temporal_data", 
               "mean_temporal_difference", "max_temporal_difference", "min_temporal_difference"),
    value = c(length(orf_model_results), nrow(adjusted_diff_clean),
              mean(adjusted_diff_clean, na.rm = TRUE), 
              max(adjusted_diff_clean, na.rm = TRUE), 
              min(adjusted_diff_clean, na.rm = TRUE))
  )
  
  write.csv(summary_stats, "confounder_adjusted_summary_stats.csv", row.names = FALSE)
}

cat("\nConfounder-adjusted temporal analysis completed successfully!\n")
cat("Generated files:\n")
cat("- confounder_adjusted_temporal_heatmap.png: Model-based temporal differences\n")
cat("- temporal_vs_limma_validation.png: Validation against limma results\n")
cat("- confounder_adjusted_temporal_matrix.csv: Data matrix\n")
cat("- temporal_limma_validation.csv: Validation correlation results\n")
cat("- confounder_adjusted_summary_stats.csv: Summary statistics\n")

cat("\nAnalysis completed at:", format(Sys.time()), "\n")